<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <title>Craig Stuntz - How to Keep a Secret</title>
        <link rel="stylesheet" type="text/css" href="../css/default.css" />
        <link rel="alternate" type="application/rss+xml" title="Craig Stuntz's blog" href="../feed.xml">
        <link rel="alternate" type="application/atom+xml" title="Craig Stuntz's blog" href="../atom.xml">
        <link rel="me" href="https://discuss.systems/@CraigStuntz">
        <!-- KaTeX -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
        <!-- The loading of KaTeX is deferred to speed up page rendering -->
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
            <!-- To automatically render math in text elements, include the auto-render extension: -->
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
    </head>
    <body>
        <div id="header">
            <div id="logo">
                <a href="../">Craig Stuntz</a>
            </div>
            <div id="navigation">
                <a href="../">Home</a>
                <a href="../about.html">About</a>
                <a href="../presentations.html">Presentations</a>
                <a href="../archive.html">Archive</a>
            </div>
        </div>

        <div id="content">
            
            
                <h1>How to Keep a Secret</h1>
            
            <div class="info">
    Posted on August 30, 2024
    
</div>

<p>As software developers, we are regularly tasked with keeping secrets, such as
passwords, certificates, API credentials, signing keys, etc. We know that
you shouldn’t just check them into a git repository. But are the alternatives,
like, say, adding them as GitHub Actions Environment Secrets, really any better?
Keeping secrets secure is one of the things we need to get right, and getting it
“mostly correct” is not good enough.</p>
<p>When asked to keep a secret secure, the first instinct of the average programmer
is to put it behind a password.
<a href="https://regex.info/blog/2006-09-15/247">As the saying goes</a>, “Now you have two
problems.” How can we actually improve security?</p>
<p>Secrets are more complicated than they might at first glance seem, in part
because there are so many different types of secret.</p>
<div class="highlight">
<p>However, there is one key
fact which we can use to simplify the entire enterprise, which is that an
effective way of keeping secrets, well, secret, is to <em>have fewer secrets.</em></p>
</div>
<p>In
this post, we will examine some practical ways of reducing the number of secrets
we must keep, and some better ways to deal with those that remain.</p>
<h2 id="what-is-a-secret">What Is a Secret?</h2>
<p>A secret is any value which you only want to disclose to certain individuals or
systems, and where the disclosure of that value is itself a security compromise.</p>
<p>One of the recurring themes of this article will be that not all secrets are the
same, so let’s first consider some things which you might want to keep secret:</p>
<ul>
<li>Passwords</li>
<li>ATM PINs</li>
<li><a href="https://www.dol.gov/general/ppii">PII</a></li>
<li>TLS certificates</li>
<li>API Keys (“client secrets”)</li>
<li>Proprietary code (or access to same)</li>
<li>SSH keys</li>
</ul>
<p>…and many others!</p>
<h2 id="is-there-a-silver-bullet-solution">Is There a “Silver Bullet” Solution?</h2>
<p>The programming profession has developed a variety of different ways to deal
with secret-keeping over the years, including:</p>
<ul>
<li><strong>Hash passwords</strong> using bcrypt or scrypt and then store the hash</li>
<li><strong>Store passwords</strong> in 1Password/Chrome Password Manager/macOS Keychain, etc.</li>
<li><strong>Third party services</strong> such as Azure Key Vault or AWS SSM Encrypted Parameters</li>
<li>An <strong><a href="https://en.wikipedia.org/wiki/Hardware_security_module">HSM</a> or
<a href="https://www.microsoft.com/en-us/security/business/security-101/what-is-privileged-access-management-pam">PAM</a></strong> solution, such as CyberArk or Delinea</li>
<li><strong><a href="https://www.scrum.org/resources/blog/minimum-viable-product-or-minimum-inspectable-increment">MVP</a>
solutions</strong>, like Docker Secrets or GitHub Actions Environment Secrets</li>
<li><strong>Physical security</strong>, such as putting passwords in a safe</li>
</ul>
<p>All of these “solutions” do some things well, and are wildly unsuitable in other
cases:</p>
<ul>
<li>bcrypt &lt;- can’t decrypt, so unsuitable for client secrets</li>
<li>Chrome Password Manager &lt;- not intended for non-interactive (service) use, must trust vendor</li>
<li>Cloud services &lt;- Costs money, not available on all devices, mostly useful for client secrets</li>
<li>HSMs/PAMs &lt;- Expensive, centralized design might make outages catastrophic</li>
<li>MVP solutions &lt;- Tend to put ease of use over security in order to provide a viable alternative to keeping secrets in plaintext</li>
<li>Physical security &lt;- How do you get it when you need it?</li>
</ul>
<p>Every method of dealing with a secret has downsides. You need to choose the right
compromise for your threat model, presuming that you cannot eliminate the secret.</p>
<p>What’s more, even if you do <em>literally everything right,</em> your secrets may still
be stolen. For example, a threat actor who Microsoft calls Storm-0558 was
<a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">able to access Exchange email boxes by forging security tokens through compromise of a Microsoft key</a>.
In this case, the owners of the Exchange Online email servers were following
good practices and had delegated the security of their secrets to a much larger,
technically competent, and well-resourced entity (Microsoft), and had their
secrets stolen anyway.</p>
<p>So perhaps we should be asking not “Is there a magic solution for all secrets,”
but rather “Is there any solution for <em>any</em> secret?”</p>
<h2 id="eliminate-the-secret">Eliminate the Secret!</h2>
<p>The answer is yes: If you can eliminate the secret altogher then you prevent
its theft.</p>
<p>Although 100% of secrets in an organization cannot be eliminated, a surprising
number can. Let’s take a look at some practical examples.</p>
<ul>
<li>Get rid of old PII. The default of nearly every database is to store data
forever, but ask yourself if you really need every bit of data that you
captured years ago online. You can write a nightly sweep which deletes old
records or moves them into cold storage.</li>
<li>Use <a href="https://learn.microsoft.com/en-us/azure/developer/github/connect-from-azure-identity">identity based access to cloud resources instead of client IDs/secrets</a>
in a build server.</li>
<li>Similarly, don’t give the build server direct access to create/manage cloud
resources. Instead, have a Lambda or Azure Function which has that permission
and trigger that function on a queue that the build server can put messages
on.</li>
<li>Control access to a database using
<a href="https://learn.microsoft.com/en-us/azure/app-service/tutorial-connect-msi-azure-database?tabs=sqldatabase-sc%2Cuserassigned-sc%2Cdotnet%2Cdotnet-mysql-mi%2Cdotnet-postgres-mi%2Cwindowsclient">managed identity instead of with a password</a>.</li>
</ul>
<h2 id="threat-modeling">Threat Modeling</h2>
<p>However, there’s a subtlety here that I don’t want to gloss over. The PII that
one system stores is different than the PII in other systems, and the
consequences of the compromise of one secret is not the same as the compromise
of another. The threat models of irs.gov, Microsoft Azure, and Bob’s
Pizza, LLC, are all different.</p>
<p>Your threat model should guide every security decision you make. A threat model is:</p>
<ul>
<li>What you have, technically</li>
<li>Who (which people) you are protecting</li>
<li>The specific bad actors who will attack you</li>
</ul>
<p>All secrets that your software or system keeps should be in your threat model.
For each threat in the threat model, you must make one of four possible decisions:</p>
<ul>
<li><strong>Accept</strong> the threat. Choose to do nothing, often because the risk is low and “you
have bigger fish to fry.” Keep the threat in the threat model, though!</li>
<li><strong>Eliminate</strong> the threat altogether. Stop using or storing the secret, for example.</li>
<li><strong>Mitigate</strong> the threat. E.g., “We reduce brute force attacks through use of a
<a href="https://en.wikipedia.org/wiki/Web_application_firewall">WAF</a>.”</li>
<li><strong>Transfer</strong> the threat. E.g., “We use Azure infrastructure to manage our TLS
private keys and never give direct access to them to our own employees.”</li>
</ul>
<p>As the saying goes, “Your threat model is not my threat model.” Every
organization will have its own threat model, and it will change over time. Your
organization should continually revisit this.</p>
<p>When you are asked to make a change which affects the security of your product,
it’s helpful to see where that change falls within the threat model and use that
to guide you as you work.</p>
<h2 id="not-all-secrets-are-the-same">Not All Secrets Are the Same</h2>
<p>Let’s examine some general classes of secrets and where they fall within the
four possible decisions we can make for items within the threat model (which,
again are accept, eliminate, mitigate, and transfer).</p>
<h3 id="passwords">Passwords</h3>
<p>By a “password,” I mean “some value that a human being will enter to control
access to a resource.” These are different from a “client secret,” which I will
discuss later on. I feel the need to clarify this, because our industry has been
a bit free with language, and calls, for example, “a secret which a service uses
to access a database” a “password,” when really it’s a client secret. Anyway…</p>
<p>Look, passwords are a disaster. Most users use the same passwords in multiple sites.
Passwords are phishable, without a password manager, which most people don’t
use.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> However, we’re kind of stuck with them, both due to
legacy use and due to the disadvantages of some of the systems proposed to
replace passwords, such as federated identity and passkeys.</p>
<p>So we must understand passwords well, and use them correctly. Not all passwords
are the same! Some are memorized (probably your laptop password, for example),
and some are random values stored in a password manager.</p>
<p>A <em>key property</em> of a password is that it’s never necessary to store the
plaintext of the password on the server, and it should not be stored in a
decryptable form. If possible, delegate this security-sentitive work to a service
such as Authentik, Okta, Entra ID, etc. But it’s still worth understanding that
these services cannot decrypt a user’s password at all, and instead use a
mechanism such as bcrypt or scrypt to store the user’s password hash.</p>
<p>A password can be combined with MFA, but SMS MFA is also phishable.
<a href="https://www.cisa.gov/sites/default/files/publications/fact-sheet-implementing-phishing-resistant-mfa-508c.pdf">Other methods of MFA, such as FIDO keys, are not phishable</a>.</p>
<p>Beware of nebulous “best practices” regarding passwords, such as
<a href="https://passwordshamer.com/">weird rules which are depressingly common in large sites</a>.
Instead, I invite you to read
<a href="https://pages.nist.gov/800-63-4/sp800-63.html">NIST 800-63</a>, which is based on
research, clearly explains why it makes the recommendations that it does, and
overall is one of the more enjoyable and informative government standards
publications which I have read. One really useful concept from NIST 800-63 is
the “assurance level,” which ties in closely with the threat model, and in
particular the realization that everyone’s threat model is different.</p>
<h3 id="passkeys">Passkeys</h3>
<p>A <a href="https://passkey.org/">passkey</a> attempts to do a 1-for-1 substitution of
passwords with a secure, phish-resistant, usable alternative. Sounds great,
right?</p>
<p>Maybe! It’s early days yet. Support for passkeys is both very new and
<a href="https://www.corbado.com/blog/passkey-implementation-pitfalls-misconceptions-unknowns">varies by platform</a>.
Different organizations have implemented passkey support for their
sites totally differently, with some sites inexplicably still wanting a password
even after a user has logged in with a passkey.</p>
<p>The end user of a passkey must make a choice whether to store passkeys in Apple,
Google, 1Password, etc., and this choice is not always presented in a clear way.
I would not currently recommend passkeys to my “non-technical relative.”
Hopefully this changes as the technology matures.</p>
<p>But for now, I would put passkeys in the “promising, but not totally ready for
prime time” bucket.</p>
<h3 id="client-secrets">Client Secrets</h3>
<p>A client secret is a secret which a service account can use to get access to a
resource, such as an AWS access key and secret pair. At first, it would seem to
be the same as a password, but the rules for keeping a client secret secure are
totally different.</p>
<p>A <em>key property</em> of a client secret is that it must be available in decrypted
form on the server. This is totally different from how passwords are stored.</p>
<p>Also, a client secret is not usable with a FIDO MFA key, or TOTP apps
such as Google Authenticator, etc. There may be “second factors” usable with
a client secret, such as the originating IP address or mutual TLS, but they are
different than the second factors used with a password.</p>
<p>Because client secrets are not intended for use by a human, the rules regarding
rotation and complexity are entirely different from passwords. It may make sense
to require rotation of client secrets, and they need not be memorizable.</p>
<h3 id="trade-secrets">Trade Secrets</h3>
<p>A trade secret refers to information known to an employee of an organization
which is not generally known to the public and which conveys some benefit to the
organization. One example which a lot of programmers will recognize is an
organization’s source code, which is often secret.</p>
<p>The safest assumption to make with a trade secret is to assume that the secret
is compromised. This doesn’t give you permission to be reckless with your
security regarding the secret, but you should be careful about using it to store
other secrets. Groups such as Lapsu$, Nobelium/Midnight Blizzard for whatever
reason really like stealing source code. You should use a scanner such as
<a href="https://trufflesecurity.com/trufflehog">TruffleHog</a> on your repositories,
because the chances are high that your adversaries already are.</p>
<h3 id="pii">PII</h3>
<p>PII, or Personally Identifiable Information, is really simple to handle: Store as
little of it as possible, and delete it quickly as soon as you can (note that
there may be legal rules requiring you to retain <em>or</em> purge certain kinds of PII).</p>
<p>Unlike most secrets, PII must typically be presenteed as plaintext in the user
interface of an application. You should assume that it’s compromised. It’s
always a liability. If your client secrets are stolen, that’s bad, but it
probably won’t make your organization headline news. PII is a fast path to
headlines.</p>
<p>Not all PII is the same, and it isn’t the same for every site. If a site leaks
the name of its users, well, that’s one thing if it’s
<a href="https://www.csoonline.com/article/554111/database-configuration-issues-expose-191-million-voter-records.html">the names of voters</a> and quite
another thing if they’re the <a href="https://www.vpnmentor.com/news/report-confidanthealth-breach/">customers of an addiction services provider</a>.</p>
<p>For every single piece of PII that you think you need, ask if there are no
alternatives and how long it’s needed. If you are told that you need some PII,
and there is no alternative, you can ask for legal review.</p>
<p>Apple takes an interesting approach to protecting PII with their Private Cloud
Compute servers which are used to do off-device queries for Apple Intelligence.
They use special servers which have
<a href="https://www.wired.com/story/apple-private-cloud-compute-ai/">no persistent storage whatsoever</a>,
which is a fantastic way to ensure that PII is not leaked by an internal process
accidentally caching the data and an attaker being able to read that cache in the
future.</p>
<h3 id="non-secrets">Non-secrets</h3>
<p>It’s helpful to be explicit about what actually isn’t a secret. This will vary
by project and by threat model. In fact, it’s so varied I don’t even want to give
an example. The product manager might say that usernames are PII and therefore a
secret, but if the company’s reaction to them leaking is to shrug and not even
offer “free credit monitoring,” then it’s hard to consider that a secret.</p>
<h2 id="recommendations">Recommendations</h2>
<p>Have fewer secrets. Give them less power. Make policies regarding their storage
and use. For example, if your database server supports connections via managed
identity, then use that feature instead of a password/secret to connect to the
database, both as a developer and in production, from a service account.</p>
<p>Be ruthless in eliminating PII in your system. Don’t store it at all when it’s
not strictly necessary to keep it, and if you must keep it, delete it as soon
as possible.</p>
<p>Assume compromise of your trade secrets, and make them as “not valuable” as
possible. For example, use a secret scanner in a pre-commit hook to keep other
secrets out of your code.</p>
<p>Set a company policy for secret storage and beware of widely distributing
secrets by accident. Developers tend to handle a lot of secrets and will hence
tend to create “informal secret stores” in the absence of policy. Some organizations will say,
“developers need to install a lot of software, and so they need administrative
access to their machines.” But I’m a developer, and most days I’m not installing
software. Having <em>temporary</em> access to administrative privileges is just fine for
me if it’s not a hassle; in a sense this is like using <code>sudo</code>.</p>
<h3 id="build-servers">Build Servers</h3>
<p>Build servers tend to have very, very, very privileged secrets, and they don’t
necessarily do a good job of keeping them safe. Jenkins has had a kind of iffy
security track record, to put it politely, and GitHub Actions Environment
Secrets are “better than storing secrets in plaintext.” Can we do better?</p>
<p>Yes, we can, by elminating secrets! Let’s take as an example a build which runs
in GitHub Actions and which needs to check out code, build it, save an artifact,
and then deploy that artifact to production servers. By virtue of running in
GitHub Actions, the build can check out code and save an artifact without needing
a secret, but what about deployment?</p>
<p>First,
<a href="https://learn.microsoft.com/en-us/azure/developer/github/connect-from-azure-identity">GitHub Actions can connect to Azure through managed identity</a>. Second, the build <em>itself</em> does not need
to actually do the deployment, it simply needs to <em>cause deployment to happen.</em>
This distinction means that we do not need to give the build process permission
to directly control Azure infrastructure, which means we can eliminate a high
value secret. Instead, the build, which has connected to Azure via identity,
can put a message into a queue which will cause an Azure Function to actually
do the deployment. The Azure Function has permission to change infrastructure,
not the build.</p>
<h3 id="transporting-a-secret">Transporting a Secret</h3>
<p>Presuming that you can’t elminiate a secret, and have a good way of storing the
secret, how do you get it from the point of storage to the place where it is
used?</p>
<p>The classic technique is to use environment variables (or Spring properties,
etc.), and while this does have some benefits (it keeps the secret out of your
source code, and it’s easy to use temp values during development), we should ask
if we can do better. Accessing the secret from the API of the vault where it is
stored prevents areas of your application which might have access to the
environment, such as <a href="https://docs.spring.io/spring-boot/docs/2.5.6/reference/html/actuator.html">Spring Boot Actuator</a>,
from disclosing the secret. Azure Key Vault has
<a href="https://learn.microsoft.com/en-us/azure/app-service/app-service-key-vault-references?tabs=azure-cli">a way to shim this API access over use of the environment which is very convenient</a>. Using this method
you can access secrets in code as though they were environment variables, but
when deployed to Azure the actual lookup will be done using the Key Vault API
and the secret value will not be in the application’s environment.</p>
<h3 id="proactive-notice-of-secret-leaks">Proactive Notice of Secret Leaks</h3>
<p>If your secret leaks (and it’s only a matter of time, to be honest), then you
want to proactively know this so that you can rotate the secret and clean up the
mess.</p>
<p>One way to get a high-fidelity alert when your secret leaks is to use a
<a href="https://canarytokens.org">canary token</a>. For example, you can create a real AWS
client ID and secret that you can leave on a production server. If an attacker
finds it and tries it out, then the canary will send you an alert via email.
There are many different types of tokens available.</p>
<p>One of the value-adds of third-party services for secret handling is that they
will often consider additional signals when deciding when to accept a secret.
If you usually log into a site from Pennsylvania during working hours, and you
suddenly are connecting from overseas at 3 in the morning, the service may want
additional verification that it’s really you.</p>
<p>Many WAFs have built-in intelligence which can detect a brute-force password attack
against your site. There’s not much you can do about these attacks besides block
the requests, but just knowing about them can be useful.</p>
<h2 id="cheat-sheets">Cheat Sheet(s)</h2>
<p>Questions to ask when you are dealing with a secret:</p>
<ul>
<li>Can I avoid using a secret (in this place) at all? (E.g., store less PII, use federated auth.)</li>
<li>Do I understand what kind of secret is needed? (E.g., understand the difference between passwords and client secrets.)</li>
<li>Can I narrow the blast radius if leaked? (E.g., use an IAM role and limited account instead of an admin account.)</li>
<li>Can I narrow the scope of the secret use? (E.g., with “just in time” access, e.g., PAM.)</li>
<li>Can I “make it Amazon’s problem”: use an “off the shelf” service instead of writing code myself? (E.g., Okta, Authentik, Entera ID, …)</li>
<li>How do I minimize exposure of the plaintext? (E.g., use SAST, consider alternatives to environment variables)</li>
<li>How can I detect attempts to compromise the secret? (Logging, WAFs, etc.)</li>
<li>How can I proactively know if the secret is leaked? (Logging, again, and canary tokens)</li>
</ul>
<p>Finally, this is less of a “Cheat Sheet” than a “Secret Management Longread,”
but the OWASP Foundation has a <a href="https://cheatsheetseries.owasp.org/cheatsheets/Secrets_Management_Cheat_Sheet.html">Secrets Management Cheat Sheet</a>.</p>
<h2 id="have-fewer-secrets">Have Fewer Secrets!</h2>
<blockquote>
<p>“The man who can keep a secret may be wise, but he is not half as wise as the
man with no secrets to keep.”
-E. W. Howe<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
</blockquote>
<p>As we have seen, secrets are complicated, and <em>keeping</em> a secret is hard work.
Whenever we can eliminate a secret, we nearly always improve the security of our
software. So why don’t we do this by default? It can seem difficult, because
“now I have to go learn about managed identity.” Let’s just acknowledge that
this is true: Eliminating secrets is not free. But it’s almost certainly cheaper
than cleaning up after a secret is compromised.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>See, for example, <a href="https://docs.google.com/presentation/d/1KaJtB4SBaZjeUiXrWzuioGKQgUWGm1oWPnWvb0FF6iw/edit#slide=id.g11b2737de95_0_325">this study from BitWarden</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Howe, E.W., <em>Country Town Sayings,</em> 1911<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

<div class="info">
    
    Tags: <a title="All pages tagged 'security'." href="../tags/security.html" rel="tag">security</a>
    
</div>

        </div>
    </body>
</html>
